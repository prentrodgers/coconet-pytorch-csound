{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350ccc98-7e53-4dc3-9cc4-15e76597ee5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Selectively stretch and decompress segments\n",
    "<p>The goal is to enable selectively staying on one place for a longer time. This can be accomplished by selecting a segment of an array to double in size. </P>\n",
    "<p>The assumption is that we will take the segmented chorale numpy arrays in directory segmented_chorales, and load them into this notebook and mess with them. This notebook will no longer need to synthesize arrays using the model, since that is done in the notebeeks called coconet_incremental_synthesis.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c8070-c8af-45c7-8422-383ccbb0d205",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTZ5xE7jaVy0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import mido\n",
    "import time\n",
    "from midi2audio import FluidSynth\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "import muspy\n",
    "import piano \n",
    "import selective_stretching_codes\n",
    "import subprocess\n",
    "from numpy.random import default_rng\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "CSD_FILE = 'goldberg_aria1.csd'\n",
    "LOGNAME = 'goldberg5.log'\n",
    "root = 5\n",
    "mode = 'major'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e593c5-9b2b-4837-8c81-20cd24736f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_play(chorale, gain, outfile = 'test.wav', outmidi='test.mid',bpm=60): # save the chorale to midi and put up a display to play it. Fast, simple, and out of tune.\n",
    "    pad8=np.zeros((chorale.shape[0],8),dtype=int)\n",
    "    chorale = np.concatenate((chorale,pad8),axis=1) # midi likes and ending to avoid the edge case bugs.\n",
    "    midi_output = selective_stretching_codes.piano_roll_to_midi(chorale, bpm=bpm) # convert to mido object at 60 time_steps per minute, one per second.\n",
    "    music = muspy.from_mido(midi_output) # convert mido to muspy music\n",
    "    muspy.write_midi(outmidi, music) # write the midi file to disk\n",
    "    muspy.write_audio(outfile, music, 'wav', 'font.sf2', 44100, gain) # generate a wav file using fluidsynth\n",
    "    audio = Audio(outfile) # get ready to show the audio widget\n",
    "    display(audio) # display the audio widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ebd34-e5cf-4625-9ee6-16d760fe05a9",
   "metadata": {},
   "source": [
    "## See if you can load one of the segmented fantasy chorales from the store of numpy arrays\n",
    "\n",
    "Here's what this cell does:\n",
    "\n",
    "- Load the numpy array, a (7, 16, 32) structure created by the coconet-model. Each of the 7 are independent 32 1/16th note sub-chorales based on taking an actual Bach chorale, BWV 180 'Schmücke dich, o liebe Seele'. A reminder that these are 16 voice chorales made by starting with three voices of Schmücke and using the coconet model to build the fourth voice. Then taking the new voice and two other existing voices and generating another. I kept doing that until I have four four voice chorales, or a 16 voice chorale, but one where each of the four have only a very limited knowledge of the other four chorales. It's sometimes a complex mess, but it holds somewhat together by the fact that they start with a real Bach chorale, and then slowly morph it into something artificial.\n",
    "- Restore normal MIDI numbers\n",
    "- expand and concatenate the segments\n",
    "- arpeggiate it\n",
    "- make a midi from the arpeggiated chorale\n",
    "- save it\n",
    "- use Csound to generate a wav file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3b2ce-c855-4456-bd58-33d2035b75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stub = 'chorale_96' # this one has the lowest entropy score of the 16 voice artificial chorales.\n",
    "numpy_file = os.path.join('segmented_chorales', file_stub + '.npy')\n",
    "chorale = np.load(numpy_file)+30 # load a generated chorale\n",
    "concat_chorale = selective_stretching_codes.expand_and_concatenate(chorale)\n",
    "print(f'chorale.shape: {chorale.shape}, concat_chorale.shape: {concat_chorale.shape}')\n",
    "# play_chorale = transpose_up_segment(concat_chorale) # the transposition into F has already happened as has the +30\n",
    "mask = selective_stretching_codes.set_mask(randomized=True)\n",
    "arp_chorale = selective_stretching_codes.arpeggiate_and_stretch(concat_chorale,mask,3) # chorale array, mask array, and skip value maximum, could be lower\n",
    "midi_output = selective_stretching_codes.piano_roll_to_midi(arp_chorale) # convert to mido object\n",
    "music = muspy.from_mido(midi_output) # convert mido to muspy music\n",
    "muspy.write_midi(file_stub + '.mid',music)\n",
    "\n",
    "velocity = 67\n",
    "volume = 15\n",
    "tpq = 1.2 # time per quarter note = 1.2 seconds, so each 1/16th note gets .3 seconds. \n",
    "upsample = 3\n",
    "# selective_stretching_codes.piano_roll_to_csound(arp_chorale,velocity,volume,tpq,upsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0ec56-b231-4f9f-be86-249424e52c84",
   "metadata": {},
   "source": [
    "## Evaluate the chorales in segmented_chorale using muspy metrics. Search for the H with high entropy.\n",
    "<p>This will load the chorales one at a time and run the muspy metrics against the finished decoded chorale. I don't put much stock in these metrics, except for the class entropy. That one gives extra value for violating classical theory rules. I like those with character.</p><p> \n",
    "<p>This measure is derived from a paper by Wu & Yang: The Jazz Transformer on the front line: exploring the shortcomings of ai-composed music through quantitative measures.\n",
    "    <a href=\"https://arxiv.org/pdf/2008.01307.pdf\"> Shih-Lun Wu and Yi-Hsuan Yang</a>\n",
    "    \n",
    "<blockquote>\n",
    "        5.1 Pitch Class Histogram Entropy\n",
    "To gain insight into the usage of different pitches, we first\n",
    "collect the notes appeared in a certain period (e.g., a bar)\n",
    "and construct the 12-dimensional pitch class histogram\n",
    "−→h ,\n",
    "according to the notes’ pitch classes (i.e. C, C#, ..., A#, B),\n",
    "normalized by the total note count in the period such that\n",
    "P\n",
    "i\n",
    "hi = 1. Then, we calculate the entropy of\n",
    "−→h :\n",
    "H(\n",
    "−→h ) = −\n",
    "X\n",
    "11\n",
    "i=0\n",
    "hi\n",
    "log2\n",
    "(hi). (2)\n",
    "The entropy, in information theory, is a measure of “uncertainty” of a probability distribution [40], hence we adopt\n",
    "it here as a metric to help assessing the music’s quality in\n",
    "tonality. If a piece’s tonality is clear, several pitch classes\n",
    "should dominate the pitch histogram (e.g., the tonic and\n",
    "the dominant), resulting in a low-entropy\n",
    "−→h ; on the contrary, if the tonality is unstable, the usage of pitch classes\n",
    "is likely scattered, giving rise to an\n",
    "−→h with high entropy</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ead1bd-1730-4ace-9c04-db9f79dfb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next line will generate a report on the chorales. \n",
    "# You can select which voices to include, and you will get a different report.\n",
    "# For example [(0,16]) would use all the voices\n",
    "# metrics = selective_stretching_codes.print_chorale_metric_report(pick_voices=[(12,16)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290ef33-8e50-41f3-8ceb-41958d41dedd",
   "metadata": {},
   "source": [
    "## Looking for interesting places to stop and linger a while.\n",
    "\n",
    "The chorales are interesting, but begin sound too conventional. As a composer, I like to sometimes take and existing piece and make my own variations on it. Bach did it, as did Brahms, Liszt, and many other composers. One technique that I have used in the past is to find expecially interesting parts of a simple piece and draw them out more, while keeping the overall forward moving structure of the piece. I call it the 'find an interesting place stop and linger a while' method of variations. It's just one method to create a variation. In this case, I call some functions that identify sections of the chorale that are especially interesting, as a measured by the number of notes that are not in the root key, in this case F major. I identify those, then stretch them out from whatever their current time steps to something much longer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686c607-aa47-4e2f-b3cc-03360c0610e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in an interesting chorale from the collection of numpy segments\n",
    "filename = os.path.join('segmented_chorales','chorale_90.npy')\n",
    "voice_low = 8\n",
    "voice_high = 16\n",
    "print(filename)\n",
    "play_chorale = selective_stretching_codes.transpose_up_segment(selective_stretching_codes.expand_and_concatenate(np.load(filename)),30) \n",
    "play_chorale = play_chorale[voice_low:voice_high,:] # this is where you need to pick the voices\n",
    "print(f'play_chorale.shape: {play_chorale.shape}, play_chorale.dtype: {play_chorale.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78c6e7-7d22-49dc-9bfc-8d3e42481ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now double up the voices to become twice as many voices.\n",
    "play_chorale = np.concatenate((play_chorale,play_chorale),axis = 0)\n",
    "print(f'play_chorale.shape: {play_chorale.shape}, play_chorale.dtype: {play_chorale.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac61cd34-5a82-4901-b2d7-4fda4292a05c",
   "metadata": {},
   "source": [
    "## Make the chorale longer: factor = 1 2x as long, factor = 2, 3x as long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b18c2a-3b30-4d50-b492-ff91779c9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before you do the discover, stretch the chorale out by making it 4 times as long.\n",
    "start_decompress = 0\n",
    "end_decompress = play_chorale.shape[1]\n",
    "factor = 1\n",
    "print(f'play_chorale.shape: {play_chorale.shape}')\n",
    "play_chorale = selective_stretching_codes.decompress_segment(play_chorale,start_decompress,end_decompress,factor=factor) \n",
    "print(f'play_chorale.shape: {play_chorale.shape}, play_chorale.dtype: {play_chorale.dtype}')\n",
    "\n",
    "print(f'Decompression by a factor of {factor} results in change by a factor of: {play_chorale.shape[1]/end_decompress}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a773e3-d2d4-437f-9827-31f226c09b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to find the the in tune time_steps, and challenging time_steos: range_in_tune and the range_of_steps\n",
    "scores = selective_stretching_codes.assign_scores_to_time_steps(play_chorale)\n",
    "range_of_steps = selective_stretching_codes.find_challenging_time_steps(scores)\n",
    "range_in_tune = selective_stretching_codes.find_in_tune_time_steps(play_chorale, range_of_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa82fb-9b7b-46f4-9b2e-2ffa2e89410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give me a set of random numbers from 2 up to but not including 8\n",
    "factors = rng.integers(low=2,high=8,size=range_of_steps.shape[0])\n",
    "print(f'factors: {factors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c1a0c2-aae7-4d29-a2fd-a9e2ed20657f",
   "metadata": {},
   "source": [
    "## Now that those segments have been decompressed, I need to refer to them to choose a theme to repeat.\n",
    "\n",
    "We know where they were in the original, we also know their locations in the expanded set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a254a-0bc5-498f-8de6-b6e0af34aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "decom_chorale, challenging_steps, in_tune_steps = selective_stretching_codes.expand_challenging_time_steps(play_chorale, range_of_steps, range_in_tune)\n",
    "\n",
    "# s = 0\n",
    "# for steps in (challenging_steps):\n",
    "#     print(f'in_tune_steps[{s}]:     {in_tune_steps[s,2:4]}, size: {in_tune_steps[s,3] - in_tune_steps[s,2]}')\n",
    "#     print(f'challenging_steps[{s}]: {challenging_steps[s,2:4]}, size: {challenging_steps[s,3] - challenging_steps[s,2]}')\n",
    "#     s += 1\n",
    "# print(f'in_tune_steps[{s}]:     {in_tune_steps[s,2:4]}, size: {in_tune_steps[s,3] - in_tune_steps[s,2]}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac7fc37-a00b-4e30-9252-824f5db0537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_time_step_in_arp = 3 # Arpeggiate one time, then skip the next three, then arpegiate the next, and so on.\n",
    "mask = rng.integers(low=0, high=2, size=(16,16), dtype=np.uint8)\n",
    "arp_chorale = selective_stretching_codes.arpeggiate_and_stretch(decom_chorale,mask,skip_time_step_in_arp)\n",
    "tpq = 1.2 # time per quarter note.\n",
    "upsamp = 4 # the higher the more mellow the sound\n",
    "velocity_base = 67 # this cents the middle velocity sample from the Bosendorfer set\n",
    "volume = 12 # avoid distortion. Slowly increse this until the overall amps gets close to but not over 32k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5bdfde-5570-4b7a-b01e-41b162e738db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if selective_stretching_codes.valid_midi(arp_chorale): \n",
    "    # selective_stretching_codes.piano_roll_to_csound(arp_chorale,velocity_base,volume,tpq,upsamp)\n",
    "    quick_play(arp_chorale, 2, outfile = 'test', outmidi='test.mid',bpm=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3e06c-6af7-4f0e-b7bb-333debbaa41e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convolve with the impulse response from Teatro Alcorcon in Madrid from Angelo Farina Collection\n",
    "<p>The next few cells require a great deal of installation work to accomplish. You need to install the following:\n",
    "    \n",
    "- Csound - available in most Linux repos with the operating system's standard program installer\n",
    "    - sudu dnf install csound-devel\n",
    "- sox \n",
    "- ffmpeg\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c17048-74ad-49cb-94de-89171d90b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 15\n",
    "!csound goldberg_aria1c.csd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6931ea7-aa06-4e23-912b-5df484d28b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lth /home/prent/Music/sflib/goldberg_aria1a-c.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4811db-f355-47cf-be75-126f31dd2abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sox /home/prent/Music/sflib/goldberg_aria1a-c.wav save1.wav reverse\n",
    "!sox save1.wav save2.wav silence 1 0.01 0.01\n",
    "!sox save2.wav save1.wav reverse\n",
    "!sox save1.wav /home/prent/Music/sflib/goldberg_aria1-t15.wav silence 1 0.01 0.01\n",
    "!rm save1.wav\n",
    "!rm save2.wav\n",
    "!ls -lth /home/prent/Music/sflib/goldberg_aria1-t14.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99335d-d06a-478b-ac8c-08954f545601",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -y -i /home/prent/Music/sflib/goldberg_aria1-t15.wav\\\n",
    "    -b:a 320k /home/prent/Music/sflib/goldberg_aria1-t15.mp3\n",
    "audio = Audio('/home/prent/Music/sflib/goldberg_aria1-t15.mp3')\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefe525-5d92-4fb2-a3ab-be37a4b521cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
