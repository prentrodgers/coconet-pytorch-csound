{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "350ccc98-7e53-4dc3-9cc4-15e76597ee5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Selectively stretch and decompress segments\n",
    "<p>The goal is to enable selectively staying on one place for a longer time. This can be accomplished by selecting a segment of an array to double in size. </P>\n",
    "<p>The assumption is that we will take the segmented chorale numpy arrays in directory segmented_chorales, and load them into this notebook and mess with them. This notebook will no longer need to synthesize arrays using the model, since that is done in the notebeeks called coconet_incremental_synthesis.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c8070-c8af-45c7-8422-383ccbb0d205",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTZ5xE7jaVy0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import mido\n",
    "import time\n",
    "from midi2audio import FluidSynth\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "import muspy\n",
    "import piano as p\n",
    "import selective_stretching_codes as s\n",
    "import samples_used as su\n",
    "import subprocess\n",
    "from numpy.random import default_rng\n",
    "rng = np.random.default_rng()\n",
    "soundfont = '../font.sf2' # you will need to download this from location specified in the github README.md\n",
    "CSD_FILE = 'goldberg_aria1.csd'\n",
    "LOGNAME = 'goldberg5.log'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0ebd34-e5cf-4625-9ee6-16d760fe05a9",
   "metadata": {},
   "source": [
    "## See if you can load one of the segmented fantasy chorales from the store of numpy arrays\n",
    "\n",
    "Here's what this cell does:\n",
    "\n",
    "- Load the numpy array, a (7, 16, 32) structure created by the coconet-model. Each of the 7 are independent 32 1/16th note sub-chorales based on taking an actual Bach chorale, BWV 180 'Schmücke dich, o liebe Seele'. A reminder that these are 16 voice chorales made by starting with three voices of Schmücke and using the coconet model to build the fourth voice. Then taking the new voice and two other existing voices and generating another. I kept doing that until I have four four voice chorales, or a 16 voice chorale, but one where each of the four have only a very limited knowledge of the other four chorales. It's sometimes a complex mess, but it holds somewhat together by the fact that they start with a real Bach chorale, and then slowly morph it into something artificial.\n",
    "- Restore normal MIDI numbers\n",
    "- expand and concatenate the segments back their original length. You have to pass a data structure to the expand_and_concatenate function that describes the current and desired length for all the segments. Their current lengths are always 32, since that is what comes out of the model. The desired length is what you would like to be the length of the segment. The function can only extend the length of the model by doubling the last 8 or more time_steps. It's doesn't have any other capabilities.\n",
    "- transpose it back to its original key\n",
    "- arpeggiate it\n",
    "- make a midi from the arpeggiated chorale\n",
    "- save it\n",
    "- use Csound or MIDI player to generate a wav file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02212f-1814-4f36-9f8f-1ce0dac7727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the chorale from the midi file\n",
    "# #  wake up                 0       1       2       3       4       5      6       7      \n",
    "# expand_codes = np.array([[32,32],[32,32],[32,32],[32,32],[32,32],[32,32],[32,32],[32,32]])\n",
    "# file_name = os.path.join('midi_files', 'Wake up, wake up, you sleepers.mid')\n",
    "# SEGMENTS = 8 # wake up and dearest have 8 phrases and schmucke has 9 32 1/16th note phrases \n",
    "#\n",
    "file_name = os.path.join('midi_files', 'schmucke.mid')\n",
    "SEGMENTS = 9\n",
    "# schmucke                0       1       2       3       4       5       6       7       8\n",
    "expand_codes = np.array([[32,40],[32,40],[32,40],[32,40],[32,40],[32,40],[32,32],[32,32],[32,32]])\n",
    "#\n",
    "# file_name = os.path.join('midi_files', 'Dearest_Jesus.mid') \n",
    "# SEGMENTS = 6\n",
    "# #  dearest                0       1       2       3       4       5      \n",
    "# expand_codes = np.array([[32,32],[32,48],[32,32],[32,48],[32,32],[32,48]])\n",
    "sample, root, mode = s.midi_to_input(file_name) # sample is time interval, voice\n",
    "keys = ['C ','C#','D ','D#','E ','F ','F#','G ','G#','A ','A#','B ']\n",
    "print(f'{file_name}, \\n{keys[root]} {mode} transposed into C and then used to create the segments')\n",
    "print(f'sample.shape: {sample.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c1729-b9d0-4fea-99e6-0ea3e92ee249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play a midi file version of the chorale\n",
    "s.quick_play(s.transpose_up_segment(sample.transpose(),root),3) # transpose from the key the model wants into the original root key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112debc-cef2-480f-9cac-f79398459ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample is a piano roll of pitches in 1/16th note intervals of dimension (240 time intervals, 4 voices, 1 pitch per time interval and voice)\n",
    "# This cell divides the chorale into phrases at or above 32 1/16th note segments. \n",
    "print(f'sample.shape: {sample.shape}')\n",
    "# Dearest Jesus does not require this concatenation\n",
    "# this is for schmucke\n",
    "sample = np.concatenate((sample, np.zeros((16,4))),axis=0) # Schmucke chorale needs a bit more at the end.\n",
    "print(f'sample.shape: {sample.shape}')\n",
    "seg_num = 0 # index into the segment array\n",
    "max_seg_size = max(expand_codes[:,1])\n",
    "min_seg_size = min(expand_codes[:,0])\n",
    "max_pad = max_seg_size - min_seg_size\n",
    "segment = np.zeros((SEGMENTS,4,max_seg_size),dtype=int)  # seg_num, voices, 1/16th note values\n",
    "print(f'max_seg_size: {max_seg_size}, min_seg_size: {min_seg_size}, max_pad: {max_pad}')\n",
    "pad_out = np.zeros((max_pad,4),dtype=int) # zeros to fill out the segment to max_seg_size\n",
    "i = 0\n",
    "current_location = 0\n",
    "for seg in segment: \n",
    "    start = expand_codes[i,0] # the number of 1/16th notes that can be sent through the model\n",
    "    end = expand_codes[i,1] # the number of 1/16th notes that the phrase provides\n",
    "    print(f'segment: {i}. start: {start}, end: {end}, current_location: {current_location}')\n",
    "    if end == max_seg_size: # no padding required\n",
    "        transfer = sample[current_location:current_location + end]\n",
    "    else: # need some padding and a concatenation\n",
    "        pad_len = max_seg_size - end  # how much padding the phrases need to reach the maximum segment length\n",
    "        pad_shape = pad_out[0:pad_len,0:4]\n",
    "        transfer = np.concatenate((sample[current_location:current_location + end], pad_shape),axis=0)\n",
    "    current_location += end\n",
    "    segment[i] = transfer.transpose() \n",
    "    i += 1\n",
    "print(f'segment.shape: {segment.shape}')\n",
    "print(f'current_location at the end: {current_location}')\n",
    "print(f'last segment first voice. segment[{i-1},0,:]: {segment[i-1,0,:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43cb535-a202-4364-b9d8-bc1b3eb1a9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just for Schmucke, we need to delete segments 2 & 3, since those are repeats, and reduce the SEGMENTS down to 7.\n",
    "SEGMENTS = 7\n",
    "print(f'expand_codes: {expand_codes}')\n",
    "expand_codes = expand_codes[2:]\n",
    "print(f'expand_codes: {expand_codes}')\n",
    "print(f'segment.shape: {segment.shape}')\n",
    "segment = segment[2:]\n",
    "print(f'segment.shape: {segment.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b95113-0174-402e-bbb3-a38f06ee6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the segments are longer than the 32 1/16th notes, so they have to be compressed. I do that by taking every other\n",
    "# note from the end of the chorale, based on the sizes speficied in the array expand_codes.\n",
    "max_seg_size = max(expand_codes[1])\n",
    "min_seg_size = min(expand_codes[1])\n",
    "print(f'max_seg_size: {max_seg_size}, min_seg_size: {min_seg_size}')\n",
    "compress_segment = np.zeros((segment.shape[0],4,32),dtype=int) # match the input segment, but only 32 notes\n",
    "i = 0\n",
    "if max_seg_size > min_seg_size:\n",
    "    for cur_seg in segment: \n",
    "        print(f'i: {i}')\n",
    "        if expand_codes[i,1] == expand_codes[i,0]: # no expansion needed\n",
    "            compress_segment[i] = cur_seg[:,:32]\n",
    "        else:\n",
    "            print(f'segment {i}. cur_seg.shape: {cur_seg.shape}')\n",
    "            print(f'cur_seg: {cur_seg[:1,-24:]}')\n",
    "            end = expand_codes[i,1]\n",
    "            start = expand_codes[i,0] + (expand_codes[i,0] - end) # 32 + - 8 = 24\n",
    "            print(f'compress from {cur_seg.shape[1]} to {expand_codes[0]}. Start at {start} take every other note')\n",
    "            compress_segment[i] = s.compress_segment(cur_seg, start, expand_codes[i,1]) \n",
    "            print(f'compressed {expand_codes[i,1]} to {expand_codes[i,0]} and store it in compress_segment.shape: {compress_segment.shape}')\n",
    "            print(f'compress_segment[{i},:1,-24:]: {compress_segment[i,:1,-24:]}')\n",
    "        i += 1\n",
    "else:\n",
    "    compress_segment = segment \n",
    "\n",
    "sub_segment = compress_segment[:,:,:32] # This is only if you don't want to do compression, just truncation.\n",
    "print(f'sub_segment.shape: {sub_segment.shape}') # it's now (segments, voices, notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532dfbe-bb1b-4662-938b-2411ad9698c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now expand the chorale back to it's uncompressed shape, concatenated into one long (voices,notes) array.\n",
    "# It looses some 1/16 notes in the compressed section.\n",
    "chorale = \\\n",
    "    s.expand_and_concatenate(sub_segment, expand_codes) # decompress \n",
    "print(f'chorale.shape: {chorale.shape}')  # now it's all one continuous (voices,notes) array\n",
    "# now tranpose it back to the original key\n",
    "chorale = s.transpose_up_segment(chorale,root) \n",
    "s.quick_play(chorale,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baefacaf-b441-448e-a98b-d357f5bdd389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the original chorale as written\n",
    "print(f'sub_segment.shape: {sub_segment.shape}')\n",
    "new_voices = sub_segment\n",
    "filename = os.path.join('schmucke_chorales','chorale_HP800100.npy')\n",
    "print(f'Original chorale. Saving to {filename}')\n",
    "np.save(filename,new_voices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2080bf6-6bb8-4e47-baa1-274ab96afc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have three directories filled with numpy arrays of (segments, voices, notes) \n",
    "# each directory has one file that represents the chorale as written, but compressed down to no more than 32 notes per phrase\n",
    "# I have to decompress them before playing them.\n",
    "as_written_chorale = 'chorale_HP800100'\n",
    "numpy_file = os.path.join('schmucke_chorales', as_written_chorale + '.npy')\n",
    "\n",
    "chorale = np.load(numpy_file)\n",
    "print(f'chorale.shape: {chorale.shape}')\n",
    "chorale = \\\n",
    "    s.expand_and_concatenate(chorale, expand_codes) # decompress \n",
    "chorale = s.transpose_up_segment(chorale,root) \n",
    "print(f'chorale.shape: {chorale.shape}')\n",
    "s.quick_play(chorale,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0ec56-b231-4f9f-be86-249424e52c84",
   "metadata": {},
   "source": [
    "## Evaluate the chorales in segmented_chorale using muspy metrics. \n",
    "\n",
    "### Search for the \"H\" with high pitch class entropy.\n",
    "\n",
    "This will load the chorales one at a time and run the muspy metrics against the finished decoded chorale. I don't put much stock in these metrics, except for the class entropy. That one gives extra value for violating classical theory rules. I like those with character.\n",
    "\n",
    "This measure is derived from a paper by Wu & Yang: The Jazz Transformer on the front line: exploring the shortcomings of ai-composed music through quantitative measures.\n",
    "    <a href=\"https://arxiv.org/pdf/2008.01307.pdf\"> Shih-Lun Wu and Yi-Hsuan Yang</a>\n",
    "    \n",
    "<blockquote>\n",
    "        5.1 Pitch Class Histogram Entropy\n",
    "To gain insight into the usage of different pitches, we first\n",
    "collect the notes appeared in a certain period (e.g., a bar)\n",
    "and construct the 12-dimensional pitch class histogram\n",
    "−→h ,\n",
    "according to the notes’ pitch classes (i.e. C, C#, ..., A#, B),\n",
    "normalized by the total note count in the period such that\n",
    "P\n",
    "i\n",
    "hi = 1. Then, we calculate the entropy of\n",
    "−→h :\n",
    "H(\n",
    "−→h ) = −\n",
    "X\n",
    "11\n",
    "i=0\n",
    "hi\n",
    "log2\n",
    "(hi). (2)\n",
    "The entropy, in information theory, is a measure of “uncertainty” of a probability distribution [40], hence we adopt\n",
    "it here as a metric to help assessing the music’s quality in\n",
    "tonality. If a piece’s tonality is clear, several pitch classes\n",
    "should dominate the pitch histogram (e.g., the tonic and\n",
    "the dominant), resulting in a low-entropy\n",
    "−→h ; on the contrary, if the tonality is unstable, the usage of pitch classes\n",
    "is likely scattered, giving rise to an\n",
    "−→h with high entropy</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ead1bd-1730-4ace-9c04-db9f79dfb481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next line will generate a report on the chorales. \n",
    "# You can select which voices to include, and you will get a different report.\n",
    "# For example [(0,16]) would use all the voices\n",
    "# the directory should contain only those with the same dimensions, such as all (6,16,32) for Dearest Jesus\n",
    "# or all (7,16,32) for Schmucke\n",
    "# sorting is done to have the highest class entropy at the top.\n",
    "dirname = 'schmucke_chorales'\n",
    "print(expand_codes)\n",
    "metrics = s.print_chorale_metric_report(dirname,0,16,expand_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290ef33-8e50-41f3-8ceb-41958d41dedd",
   "metadata": {},
   "source": [
    "## Looking for interesting places to stop and linger a while.\n",
    "\n",
    "The chorales are interesting, but begin sound too conventional. As a composer, I like to sometimes take and existing piece and make my own variations on it. Bach did it, as did Brahms, Liszt, and many other composers. One technique that I have used in the past is to find expecially interesting parts of a simple piece and draw them out more, while keeping the overall forward moving structure of the piece. I call it the 'find an interesting place stop and linger a while' method of variations. It's just one method to create a variation. In this case, I call some functions that identify sections of the chorale that are especially interesting, as a measured by the number of notes that are not in the root key, in this case F major. I identify those, then stretch them out from whatever their current time steps to something much longer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb32454-757f-43d9-89fa-d75453652ee0",
   "metadata": {},
   "source": [
    "# Preferred order of the manipulation layers:\n",
    "\n",
    "1. Load the numpy array into a variable: <code>chorale = np.load(os.path.join('dearest_jesus_chorales','chorale_HP80029.npy')) + 30</code>\n",
    "2. Set the expand codes based on the original chorale: <code>expand_codes = np.array([[32,32],[32,48],[32,32],[32,48],[32,32],[32,56]])</code>\n",
    "3. Restore the original phrase lengths: <code>chorale = s.expand_and_concatenate(chorale[:,8:16,:], expand_codes)</code>\n",
    "4. Restore the original key: <code>chorale = s.transpose_up_segment(chorale,root)</code>\n",
    "5. Get the scores for each time_step: <code>scores = s.assign_scores_to_time_steps(chorale, root, mode)</code>\n",
    "6. Determine the steps to expand and those to retain as is. You might want to do this once for each 4 voice chorale.\n",
    "            <code>range_of_steps = s.find_challenging_time_steps(scores)</code>\n",
    "            <code>range_in_tune = s.find_in_tune_time_steps(chorale, range_of_steps)</code>\n",
    "7. Lengthed the challenging sections:<code>chorale, challenging_steps, in_tune_steps = s.expand_challenging_time_steps(chorale, range_of_steps, range_in_tune, high = 15) # where high is the maximum to expand</code>\n",
    "8. Double the length of the chorale: <code>chorale = np.concatenate((chorale[:4,:], chorale[4:]),axis=1) </code>\n",
    "9. Double the density from 4 to 8 voices: <code>chorale = np.concatenate((chorale,chorale),axis = 0)</code>\n",
    "10. Arpeggiate it: <code>chorale = s.arpeggiate(chorale,rng.integers(low=0, high=2, size=(8,8), dtype=np.uint8),3)</code>\n",
    "11. Play it: <code>s.piano_roll_to_csound(chorale,67,15,1,4,challenging_steps, zfactor=18)</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e32cb-f968-41b4-bb3d-3596ecad5489",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stub = 'chorale_HP80035.npy' # Highest pitch entropy\n",
    "dirname = 'schmucke_chorales'\n",
    "print(f'root: {root}, mode: {mode}')\n",
    "chorale = np.load(os.path.join(dirname,file_stub)) + 30\n",
    "print(f'shape of chorale after loading: chorale.shape: {chorale.shape}')\n",
    "chorale = s.expand_and_concatenate(chorale, expand_codes)\n",
    "print(f'shape of chorale after restore original phrase lengths: chorale.shape: {chorale.shape}')\n",
    "chorale = s.transpose_up_segment(chorale,root)\n",
    "\n",
    "masks = np.array([[16,18,2,6,3],[16,18,4,4,2],[16,20,1,4,3],[16,20,2,2,2]]) #these are the values to pass to the arpeggiate function\n",
    "# split the chorale into separate paths with 4 voices each\n",
    "concat_chorale = np.empty((4,0),dtype=int)\n",
    "concat_challenging_steps = np.empty((0,4),dtype=int)\n",
    "previous_size = 0\n",
    "for i in range(4): # \n",
    "    print(f'Start of expansion of section {i}',end='\\t')\n",
    "    sub_chorale = chorale[i*4:(i+1)*4,:] \n",
    "    print(f'i: {i} sub_chorale.shape: {sub_chorale.shape}')\n",
    "    scores = s.assign_scores_to_time_steps(sub_chorale, root, mode)\n",
    "    range_of_steps = s.find_challenging_time_steps(scores, sub_chorale) \n",
    "    range_in_tune = s.find_in_tune_time_steps(sub_chorale, range_of_steps)\n",
    "    sub_chorale, challenging_steps, in_tune_steps = \\\n",
    "        s.expand_challenging_time_steps(sub_chorale, range_of_steps, range_in_tune, high = 10)\n",
    "    print(f'challenging_steps.shape: {challenging_steps.shape}')\n",
    "    print(f'shape of chorale after expansion of section {i}. sub_chorale.shape: {sub_chorale.shape}')\n",
    "    sub_chorale = s.arpeggiate(sub_chorale,s.shaded_mask((masks[i,0],masks[i,1]),masks[i,2],masks[i,3]),masks[i,4])\n",
    "    concat_chorale = np.concatenate((concat_chorale, sub_chorale),axis = 1) # add this chorale to the chain of chorales\n",
    "    challenging_steps += previous_size # zero at first, the next steps are boosted before concatenation, all four indeciis are boosted\n",
    "    previous_size += sub_chorale.shape[1] # then all the values are increased next time through\n",
    "    concat_challenging_steps = np.concatenate((concat_challenging_steps,challenging_steps),axis=0)\n",
    "    print(f'concat_challenging_steps.shape: {concat_challenging_steps.shape}')\n",
    "    s.report_expansion(scores, range_of_steps, challenging_steps, sub_chorale, concat_challenging_steps, lines = 250)\n",
    "                                                                            \n",
    "print(f'shape of chorale after expansion, lengthening, and concatenation: concat_chorale.shape: {concat_chorale.shape}')\n",
    "chorale = np.concatenate((concat_chorale,concat_chorale),axis = 0) # double the voices from 4 to 8.\n",
    "chorale = s.octave_shift(s.octave_shift(chorale, 0.15, 45), 0.15, 33) # 15% of the time increase the octave of a note, clump the changes in groups of 33 and 45\n",
    "print(f'shape of chorale after increasing voices: chorale.shape: {chorale.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648de2e-07e9-425c-978f-050a52835d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.piano_roll_to_csound(chorale, 65, 13, 1.05, 3, concat_challenging_steps, zfactor=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7b194-27d3-4feb-a502-6902824c5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 36\n",
    "!csound goldberg_aria1c.csd\n",
    "!ls -lth /home/prent/Music/sflib/goldberg_aria1a-c.wav\n",
    "!sox /home/prent/Music/sflib/goldberg_aria1a-c.wav save1.wav reverse\n",
    "!sox save1.wav save2.wav silence 1 0.01 0.01\n",
    "!sox save2.wav save1.wav reverse\n",
    "!sox save1.wav /home/prent/Music/sflib/goldberg_aria1-t36.wav silence 1 0.01 0.01\n",
    "!rm save1.wav\n",
    "!rm save2.wav\n",
    "!ls -lth /home/prent/Music/sflib/goldberg_aria1-t36.wav\n",
    "!ffmpeg -y -i /home/prent/Music/sflib/goldberg_aria1-t36.wav\\\n",
    "    -b:a 320k /home/prent/Music/sflib/goldberg_aria1-t36.mp3\n",
    "!cp /home/prent/Music/sflib/goldberg_aria1-t36.mp3 \\\n",
    "    /home/prent/Dropbox/Uploads/goldberg_aria1-t36.mp3\n",
    "audio = Audio('/home/prent/Music/sflib/goldberg_aria1-t36.mp3')\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f34995-0a99-4d8f-b720-d5e220454e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = su.report_samples_used()\n",
    "print(f'number of samples used in the last csound run {how_many}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e6e55-9988-4e4d-b552-d2a42ac063ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1dc4f9-fa0e-4b0f-8e74-5768ec8f6329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
